{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from hyperopt.pyll import scope\n",
    "from hyperopt import space_eval\n",
    "import mlflow\n",
    "from  mlflow.tracking import MlflowClient\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://mlflowrunss3/mlflow/5', creation_time=1690388694259, experiment_id='5', last_update_time=1690388694259, lifecycle_stage='active', name='diabetes_prediction_project', tags={}>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROJECT_NAME = f\"diabetes_prediction_project\"\n",
    "mlflow.set_tracking_uri(\"http://78.47.114.227:7060\")\n",
    "mlflow.set_experiment(experiment_name=PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../dataset/diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['new_feature_1'] = data['BMI'] / data['DiabetesPedigreeFunction']\n",
    "data['new_feature_2'] = data['Glucose'] + data['BloodPressure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.drop(['Outcome'], axis=1)\n",
    "y_train = data['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "    test_size=0.25, random_state= 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = lgb.Dataset(X_train, label=y_train)\n",
    "valid = lgb.Dataset(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model\", \"lgbm\")\n",
    "        mlflow.log_params(params)\n",
    "        booster = lgb.train(\n",
    "            params=params,\n",
    "            train_set=train,\n",
    "            num_boost_round=10,\n",
    "            feval=[(X_val, 'validation')]\n",
    "            #early_stopping_rounds=50\n",
    "        )\n",
    "        y_pred = booster.predict(X_val)\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    return {'loss': rmse, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 576, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.343750  \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 576, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.343750                             \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 576, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.343750                             \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 576, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.343750                             \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 576, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.343750                             \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 576, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.343750                             \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 576, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.343750                             \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 576, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.343750                             \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 576, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.343750                             \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 576, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.343750                             \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf       \n",
      "100%|██████████| 10/10 [00:02<00:00,  5.00trial/s, best loss: 0.3998064877503185]\n"
     ]
    }
   ],
   "source": [
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "best_result = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=10,\n",
    "    trials=Trials()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://mlflowrunss3/mlflow/5/2beec30cffba4e74988e876a44964095/artifacts/artifact\n",
      "LGBMClassifier()\n",
      "{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}\n"
     ]
    }
   ],
   "source": [
    "PROJECT_NAME = \"diabetes_prediction_project\"\n",
    "mlflow.set_tracking_uri(\"http://78.47.114.227:7060\")\n",
    "client = MlflowClient()\n",
    "mlflow.set_experiment(PROJECT_NAME)\n",
    "\n",
    "registered_model_name=f\"name='{PROJECT_NAME}'\"\n",
    "registered_model_uri = client.search_model_versions(registered_model_name)[-1].source\n",
    "print(registered_model_uri)\n",
    "loaded_model = mlflow.lightgbm.load_model(model_uri=registered_model_uri)\n",
    "print(loaded_model)\n",
    "print(loaded_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
